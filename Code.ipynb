{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "2qBfDDifjDHK",
    "outputId": "a75a8fce-2dc9-45c5-b361-6c8ff78ddfee"
   },
   "outputs": [],
   "source": [
    "!pip install Pillow==5.3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "l96zPWXCERPu",
    "outputId": "d40e5bb0-6337-4a1e-e2cf-747c9e8ce199"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install Pillow==5.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hqQ2MBYuHj1e",
    "outputId": "468354cc-d1e9-4655-b0ef-320fa1611e48"
   },
   "outputs": [],
   "source": [
    "!pip install -U pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DE-heHSMsZeN"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "  for extension in extensions: register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CGtDhC09FjsB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import scipy\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KUo-gslhGwnh",
    "outputId": "5a86223b-30bf-41d8-e69b-e33210591387"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h1GiX2YWz_Bl"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('split_data.zip', 'r')\n",
    "zip_ref.extractall('data/')\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HHp1Mw5p0E51"
   },
   "outputs": [],
   "source": [
    "image_path = 'data/split_data/images/'\n",
    "depth_path = 'data/split_data/depths/'\n",
    "\n",
    "i_name = glob.glob(image_path+'*.png')\n",
    "i_id = [x.split('/')[-1] for x in i_name]\n",
    "\n",
    "i_files = [image_path+x for x in i_id]\n",
    "d_files = [depth_path+x for x in i_id]\n",
    "\n",
    "images = [cv2.imread(file) for file in i_files]\n",
    "depth = [cv2.imread(file,cv2.IMREAD_GRAYSCALE) for file in d_files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QzeHoV3LZgiq",
    "outputId": "7867546d-2582-4c50-c3da-fb99b6b55141"
   },
   "outputs": [],
   "source": [
    "print len(images), len(depth), type(images[0]), images[0].shape, depth[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aEKrPo60cQIl"
   },
   "outputs": [],
   "source": [
    "class coarseNet(nn.Module):\n",
    "    def __init__(self,init_weights=True):\n",
    "        \n",
    "        super(coarseNet, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,96,kernel_size=11,stride=4,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=5,stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=True)\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(21504, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4070)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 1, 55, 74)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "                \n",
    "class fineNet(nn.Module):\n",
    "    def __init__(self, init_weights=True):\n",
    "        \n",
    "        super(fineNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9,stride=2,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1,padding=2 )\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x[:, :, 0:55, 0:74]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B1iMSKa6cg-x"
   },
   "outputs": [],
   "source": [
    "input_height = 480\n",
    "input_width = 640\n",
    "output_height = 55\n",
    "output_width = 74\n",
    "\n",
    "class data(Dataset):\n",
    "    def __init__(self, ids, img_dir, dep_dir, transform=None):\n",
    "        self.frame = ids\n",
    "        self.img_dir = img_dir\n",
    "        self.dep_dir = dep_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.frame[idx])\n",
    "        dep_name = os.path.join(self.dep_dir, self.frame[idx])\n",
    "        image = cv2.imread(img_name)\n",
    "        depth = cv2.imread(dep_name, cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.transpose(image, (2, 1, 0))\n",
    "        depth = np.transpose(depth, (1, 0))\n",
    "        image = transform.resize(image, (3, 240,320), mode='symmetric', preserve_range=True)\n",
    "        depth = transform.resize(depth, (55,74), mode='symmetric', preserve_range=True)\n",
    "        \n",
    "        sample = {'image': image, 'depth': depth}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size,depth_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        assert isinstance(depth_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        self.depth_size = depth_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, depth = sample['image'], sample['depth']\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        h, w = depth.shape\n",
    "        if isinstance(self.depth_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.depth_size * h / w, self.depth_size\n",
    "            else:\n",
    "                new_h, new_w = self.depth_size, self.depth_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.depth_size\n",
    "        dep = transform.resize(depth, (new_h, new_w))\n",
    "        return {'image': img, 'depth': dep}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, depth = sample['image'], sample['depth']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(np.float32(image)),\n",
    "                'depth': torch.from_numpy(np.float32(depth))}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RSFDNS8IdsnS"
   },
   "outputs": [],
   "source": [
    "i_name = glob.glob('data/split_data/images/*.png')\n",
    "i_id = [x.split('/')[-1] for x in i_name]\n",
    "dataset = data(ids=i_id, img_dir='data/split_data/images/', dep_dir='data/split_data/images/') \n",
    "dataset_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9VHpQemvoGEZ"
   },
   "outputs": [],
   "source": [
    "def train_coarse_gpu(model, criterion, optimizer,dataset_loader,n_epochs,print_every):\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    print(\"Training for %d epochs...\" % n_epochs)\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss = 0\n",
    "        for data in dataset_loader:\n",
    "            inputs=data[\"image\"].cuda()\n",
    "            depths=data[\"depth\"].cuda()        \n",
    "            inputs, depths = Variable(inputs), Variable(depths)\n",
    "            optimizer.zero_grad()    \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(outputs.shape[0], outputs.shape[2], outputs.shape[3])\n",
    "            loss = criterion(outputs, depths)\n",
    "            loss += loss.data.item()\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        if epoch % print_every == 0:\n",
    "            print('[(%d %d%%) %.4f]' % (epoch, epoch / n_epochs * 100, loss))\n",
    "            print(loss, '\\n')\n",
    "    return losses\n",
    "\n",
    "def train_fine_gpu(model, coarse, criterion, optimizer,dataset_loader, n_epochs,print_every):\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    print(\"Training for %d epochs...\" % n_epochs)\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss = 0\n",
    "        for data in dataset_loader:\n",
    "            inputs=data[\"image\"].cuda()\n",
    "            depths=data[\"depth\"].cuda()        \n",
    "            inputs, depths = Variable(inputs), Variable(depths)\n",
    "            optimizer.zero_grad()                \n",
    "            y = coarse(inputs)\n",
    "            outputs = model(inputs,y)\n",
    "            loss = criterion(outputs, depths)\n",
    "            loss += loss.data.item()\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "        if epoch % print_every == 0:\n",
    "            print('[(%d %d%%) %.4f]' % ( epoch, epoch / n_epochs * 100, loss))\n",
    "            print(loss, '\\n')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "p0ALA6Ik7i_H",
    "outputId": "b3e08735-5a73-42b5-8de3-8bba7c00c761"
   },
   "outputs": [],
   "source": [
    "\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "coarse_net_gpu = coarseNet()\n",
    "coarse_net_gpu.cuda()\n",
    "optimizer_coarse = optim.Adadelta(coarse_net_gpu.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "loss = train_coarse_gpu(coarse_net_gpu, criterion, optimizer_coarse, dataset_loader, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1526
    },
    "colab_type": "code",
    "id": "ApRXLaCvUN_9",
    "outputId": "fb55661c-879b-471d-b07f-23f6ffdb1efe"
   },
   "outputs": [],
   "source": [
    "\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "fine_net_gpu = fineNet()\n",
    "fine_net_gpu.cuda()\n",
    "optimizer_fine = optim.Adadelta(fine_net_gpu.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "loss = train_fine_gpu(fine_net_gpu, coarse_net_gpu, criterion, optimizer_fine, dataset_loader, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_D9ESHdhiDQT"
   },
   "outputs": [],
   "source": [
    "def test_threshold_error(ground_truth, predicted_image, delta):\n",
    "\n",
    "    eps = 1e-9\n",
    "    ground_truth = ground_truth.reshape(-1)\n",
    "    predicted_image = predicted_image.reshape(-1)\n",
    "\n",
    "    arr1 = ground_truth / (predicted_image + eps)\n",
    "    arr2 = predicted_image / (ground_truth + eps)\n",
    "    \n",
    "    max_arr = np.maximum(arr1, arr2)\n",
    "    indicator_arr = (max_arr < delta).astype('float')\n",
    "\n",
    "    return np.mean(indicator_arr)\n",
    "  \n",
    "def scale_invariant_error(ground_truth, predicted_image):\n",
    "\n",
    "    eps = 1e-9\n",
    "    ground_truth = np.abs(ground_truth.reshape(-1))\n",
    "    predicted_image = np.abs(predicted_image.reshape(-1))\n",
    "    \n",
    "    log_ground_truth = np.log(ground_truth+eps)\n",
    "    log_predicted_image = np.log(predicted_image+eps)\n",
    "    \n",
    "    diff = log_ground_truth - log_predicted_image\n",
    "    diff_sqr = np.square(diff)\n",
    "    \n",
    "    part1 = np.mean(diff_sqr)\n",
    "    part2 = np.square(np.sum(diff_sqr)) / np.square(diff_sqr.shape[0])\n",
    "    \n",
    "\n",
    "\n",
    "    return part1 - part2\n",
    "\n",
    "def rmse_linear_error(ground_truth, predicted_image):\n",
    "  \n",
    "      ground_truth = ground_truth.reshape(-1)\n",
    "      predicted_image = predicted_image.reshape(-1)\n",
    "      \n",
    "      return np.mean(np.square(ground_truth -predicted_image))\n",
    "\n",
    "def rmse_log_error(ground_truth, predicted_image):\n",
    "      eps = 1e-9\n",
    "      ground_truth = np.log(np.abs(ground_truth.reshape(-1))+eps)\n",
    "      predicted_image = np.log(np.abs(predicted_image.reshape(-1))+eps)\n",
    "      \n",
    "      return np.mean(np.square(ground_truth -predicted_image))\n",
    "    \n",
    "def abs_relative_error(ground_truth, predicted_image):\n",
    "  \n",
    "      eps = 1e-9\n",
    "      ground_truth = ground_truth.reshape(-1)\n",
    "      predicted_image = predicted_image.reshape(-1)\n",
    "      \n",
    "      diff = ground_truth - predicted_image\n",
    "      rel_diff = np.abs(diff) / (ground_truth+eps)\n",
    "      \n",
    "      return np.mean(diff)\n",
    "\n",
    "def squared_relative_error(ground_truth, predicted_image):\n",
    "  \n",
    "      eps = 1e-9\n",
    "      ground_truth = ground_truth.reshape(-1)\n",
    "      predicted_image = predicted_image.reshape(-1)\n",
    "      \n",
    "      diff = ground_truth - predicted_image\n",
    "      rel_diff = np.square(diff) / np.abs((ground_truth+eps))\n",
    "      \n",
    "      return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "85pFA8M-7Prb",
    "outputId": "463fae1a-8257-476b-91e2-47d7b33b38fe"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "threshold_error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "          \n",
    "      threshold_error = threshold_error + test_threshold_error(outputs, depths, 1.96)\n",
    "      count = count + 1\n",
    "threshold_error /= count\n",
    "print(\"The threshold error on the test images is: \", threshold_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Hy3GJaLj9Fng",
    "outputId": "5dacadee-97b5-4460-d220-cdeb5b5173e6"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "      error = error + np.abs(scale_invariant_error(outputs, depths))\n",
    "      count = count + 1\n",
    "error = error / count\n",
    "print(\"The scale invariant error on the test images is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TJ2JgP158Aoc",
    "outputId": "0db2bdf1-d497-4006-bcd3-d4f1ccc2cacf"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "      error = error + rmse_linear_error(outputs, depths)\n",
    "      count = count + 1\n",
    "error = error / count\n",
    "print(\"The RMSE on the test images is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-o4MlFzw9IC2",
    "outputId": "d3f3903a-aa3b-44a7-b225-03667d7ce2c3"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "      error = error + rmse_log_error(outputs, depths)\n",
    "      count = count + 1\n",
    "error = error / count\n",
    "print(\"The RMSE (log) on the test images is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gsALKs5Q_6kL",
    "outputId": "3d5a3ad1-add7-4a9a-f198-66590dbed935"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "      error = error + np.abs(abs_relative_error(outputs, depths))\n",
    "      count = count + 1\n",
    "error = error / count\n",
    "print(\"The absolute relative error on the test images is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UNWh0znJADJL",
    "outputId": "8bc2869b-f523-4d45-b503-fa5d1e7b2c12"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "error = 0\n",
    "for data in dataset_loader:\n",
    "      inputs=data[\"image\"].cuda()\n",
    "      depths=data[\"depth\"].cuda()        \n",
    "      inputs, depths = Variable(inputs), Variable(depths)\n",
    "      y = coarse_net_gpu(inputs)\n",
    "      outputs = fine_net_gpu(inputs,y)\n",
    "      outputs = outputs.cpu()\n",
    "      depths = depths.cpu()\n",
    "      outputs = outputs.detach().numpy()\n",
    "      depths = depths.detach().numpy()\n",
    "      error = error + np.abs(squared_relative_error(outputs, depths))\n",
    "      count = count + 1\n",
    "error = error / count\n",
    "print(\"The squared relative error on the test images is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "j7875F-cPX8T"
   },
   "outputs": [],
   "source": [
    "class experiment_coarseNet(nn.Module):\n",
    "    def __init__(self,init_weights=True):\n",
    "        \n",
    "        super(experiment_coarseNet, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=11,stride=4,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size=5,stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=True)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn5 = nn.BatchNorm2d(256)       \n",
    "        self.fc1 = nn.Linear(21504, 4096)\n",
    "        \n",
    "        self.fc2 = nn.Linear(4096, 4070)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn5(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 1, 55, 74)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "                \n",
    "class experiment_fineNet(nn.Module):\n",
    "    def __init__(self, init_weights=True):\n",
    "        \n",
    "        super(experiment_fineNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9,stride=2,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1,padding=2 )\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = x[0, 0, 0:55, 0:74]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2296
    },
    "colab_type": "code",
    "id": "F0OpsO_uOIaV",
    "outputId": "cb97cc56-c6e2-4275-f7a6-0f8aaa08f5d7"
   },
   "outputs": [],
   "source": [
    "\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "coarse_net_gpu = experiment_coarseNet()\n",
    "coarse_net_gpu.cuda()\n",
    "optimizer_coarse = optim.Adadelta(coarse_net_gpu.parameters(), lr=1e-1)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "loss = train_coarse_gpu(coarse_net_gpu, criterion, optimizer_coarse, dataset_loader, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1980
    },
    "colab_type": "code",
    "id": "nECLbzd1OLSy",
    "outputId": "ca5f8ac9-9b5d-40db-e3b9-f7132262c253"
   },
   "outputs": [],
   "source": [
    "\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "fine_net_gpu = experiment_fineNet()\n",
    "fine_net_gpu.cuda()\n",
    "optimizer_fine = optim.Adadelta(fine_net_gpu.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "loss = train_fine_gpu(fine_net_gpu, coarse_net_gpu, criterion, optimizer_fine, dataset_loader, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CVProject.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
